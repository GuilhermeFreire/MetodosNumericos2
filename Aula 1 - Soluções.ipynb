{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soluções relativas aos execícios da Aula 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "\n",
    "$$\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\min_{v} \\norm{Ax - b}^2$$\n",
    "\n",
    "Podemos resolver esse exercício de forma similar a como resolvemos o problema da Aula 1.\n",
    "\n",
    "$$\n",
    "    \\min_{v} (Ax - b)^T (Ax - b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\min_{v} (x^TA^T - b^T) (Ax - b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\min_{v} x^TA^TAx -x^TA^Tb - b^TAx + b^Tb\n",
    "$$\n",
    "\n",
    "Tomemos agora o gradiente de $f$.\n",
    "\n",
    "$$\n",
    "    \\nabla_x f = ((A^TA) + (A^T A)^T)x - A^Tb - b^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\nabla_x f = 2A^TAx - A^Tb - b^TA\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\nabla_x f = 2(A^TAx - A^Tb)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\nabla_x f = 2A^T(Ax - b)\n",
    "$$\n",
    "\n",
    "Igualemos a expressão a zero agora.\n",
    "\n",
    "$$\n",
    "     0 = 2A^T(Ax - b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    0 = A^T(Ax - b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    A^TA = A^Tb\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "\n",
    "Esse problema também pode resolvido de forma parecida.\n",
    "\n",
    "$$\n",
    "    \\min_{c} \\norm{(a - cv)}^2\n",
    "$$\n",
    "\n",
    "Primeiro, encontremos uma função $f$ para tirar o gradiente.\n",
    "\n",
    "$$\n",
    "    f = (a - cv)^T(a - cv)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    (a^T - cv^T)(a - cv)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    a^Ta - a^Tcv - cv^Ta + cv^Tcv\n",
    "$$\n",
    "\n",
    "$$\n",
    "    a^Ta - 2c a^Tv + c^2v^Tv\n",
    "$$\n",
    "\n",
    "Agora, o gradiente.\n",
    "\n",
    "$$\n",
    "    \\nabla_c f = - 2a^Tv + 2cv^Tv\n",
    "$$\n",
    "\n",
    "Igualando a zero.\n",
    "\n",
    "$$\n",
    "    0 = - 2a^Tv + 2cv^Tv\n",
    "$$\n",
    "\n",
    "$$\n",
    "    2a^Tv = 2cv^Tv\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{a^Tv}{v^Tv} = c\n",
    "$$\n",
    "\n",
    "Semanticamente essa resposta faz sentido, visto que a projeção de $a$ em $v$ é o vetor que minimiza o \"erro\" entre $a$ e $v$, ou seja, o vetor diferença $a - v$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
